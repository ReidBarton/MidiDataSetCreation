# MIDI data collection for RNN training. #

If you have a Matlab license and want to generate text file datasets from MIDI music files for machine learning, this is for you!

>Please note this is a project that I worked on in 2017, my freshman year of college, and I am now coming back to it after a couple of years in order to document it and get it off my local machine. The documentation, code structure, and code style is poor, but it was a fun project that had interesting results.


## Basic idea behind the project: ##

MIDI <-> CSV <-> TXT <-> RNN

Take MIDI songs and convert via .csv to one large input.txt file that is fed to a recurrent neural network (RNN) for training. Once the model is trained, have it output generated "text" that is really encoded music. Then convert back up the chain to MIDI and listen to music generated by a computer. 


## What this repo includes ##

The code I wrote for this project are matlab files to facilitate the CSV <-> TXT steps. 
  - This step is important in order to give the RNN a 'dense' input. The CSVs are sparse and repetative, and the corresponding text removes that. This is helpful in traing our model faster and better because it does not have to "learn" these unncessary patterns. We want it to focus on learning the music patterns. 

I also wrote wrapper functions for MIDI <-> CSV executables. John Walker's [midicsv](http://www.fourmilab.ch/webtools/midicsv/) executables were used, and a copy of them is included in this repo for Windows.


## What this repo does not include ##

The RNN used in my experiments was Andrej Karpathy's [char-rnn](https://github.com/karpathy/char-rnn). I simply would place my input.txt files into the appropriate directory, and then run his scripts with various settings to train my models. Then the trained models would generate text file outputs that could then be turned into music.


## Repo structure & descriptions ##
```
Csvmidi.exe                               - John Walker's midicsv executable
Main.m                                    - Look here for tips
Midicsv.exe                               - John Walker's midicsv executable
README.md                                 - hello
compressRaw.m
compressedRaw2data.m
csv2midi.m
csvExtract.m
data2csv.m
data2raw.m
decompressRaw.m
example_outputs/
  1_ex_uncompressed.mid                   - Training on the uncompressed text files
  2_ex_uncompressed2.mid
  3_early_exp.mid                         - Early experiment with poor training settings 
  4_more_exp.mid
  5_probably_the_best.mid                 - The most interesting result.
  6_some_more_exp.mid
midi2csv.m
raw2data.m
songs/
  example_data_set/
    8hr_ragtime_for_training.txt          - 8hr of ragtime in compressed .txt form ready to train
    rawMega.csv                           - 1.5 hr of ragtime
    rawMega.mid  
    rawMega_compressed.txt
  input.txt                               - a file that is generated to be input to the RNN
  song(1).csv                             - one of many songs to use as input converted to .csv
  song(1).mid                             - one of many songs to use as input
```
## How this project was run, and can be used again! ##

Looking at Main.m can also guide the workflow of all the helper functions. 
- First we use `midi2csv()` to convert .midi files from our `songs/` directory and to .csv files. 

- Then we grab song meta data from the .csv files with `csvExtract()`. This allows us to adjust the song tempo and note length so that all songs have the same meta data. (This does not change how the song sounds, for example a long note in a fast tempo gets recalculated to be a short note in a slow tempo.) 

- (Optional step) We can export our song information as csv with new uniform meta data with `data2csv()`.

- We can next use `data2raw()` to take our song data variable returned from `cvsExtract()`, and dump it into a large text file.
  - Here is an example from ragtime .midi music:
  > ...
    9EWZc
    9EWZc
    9EWZc
    9E
    9E
    9E
    9E
    9E
    9EUYa
    9EUYa
    ...
  - Each 'word' represents the notes playing for a single time interval. 

- Finally we can use `compressRaw()` to greatly increse the density of the information in the text file. This creates our `input.txt` that we feed to the RNN. 
  - An example of the compressed data is: 
  > ... 9EWZcz29 9Ez5 9EUYaz23 ...
  - Now each 'word' holds two pieces of information. What note to play, and for how long, delimited by the char 'z'. 
  - If I am completely honest, I don't remeber why this was the scheme I chose, but it seems to do the job. As a brief aside, I will list some file sizes for various stages of the song data: 
    - 134 .midi songs (about 8hr of ragtime music) -> 2.77MB
    - 134 .midi songs as a .csv -> 23.5MB
    - 134 .midi songs as uncompressed raw text -> 22.34MB
    - 134 .midi songs as compressed raw text (what the RNN gets) -> 2.03MB
    - 134 .midi songs as one large .midi file with uniform meta data -> 1.90MB

- Once we run the RNN and generate some music into a text file that we want to listen to, we can run these functions in reverse. First there is `decompressRaw()`. There may be a few errors in this file if the model does not generate words in the form [Notes z #] that can be manually fixed. 

- The uncompressed file can then be turned into Matlab data with `raw2data()` and dumped into a .csv with `data2csv()`.

- Finally the .csv can be turned into music with `csv2midi()`


## Discussion ##

I worked on this project over a couple of weeks, and I had a lot of fun learning - I recall some late nights and running a couple models overnight on my laptop. It enabled me to explore some concepts in machine learning and play around with traing models with my own datasets. I was really excited to hear the output of the trained model, especially example output 5, which may admittedly be overfit. 

If you have comments, questions, or even read this far, i'd love to hear from you! 

